{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from IPython.core.display import display, HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from fake_useragent import UserAgent\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping: Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "ua = UserAgent()\n",
    "user_agent = ua.random\n",
    "print(user_agent)\n",
    "options.add_argument(user_agent)\n",
    "chromedriver = \"/Applications/chromedriver\"\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Company name- Method 1 from company review page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Data\"\n",
    "indeed_search = \"https://www.indeed.com/companies/search?q=\"\n",
    "indeed_query = indeed_search + query + \"&l=&from=discovery-cmp-search\"\n",
    "indeed_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_useragent import UserAgent\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "options = Options()\n",
    "ua = UserAgent()\n",
    "user_agent = ua.random\n",
    "print(user_agent)\n",
    "options.add_argument(f'user-agent={user_agent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(chrome_options=options, executable_path=chromedriver)\n",
    "driver.get(indeed_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_n=soup.find_all('a',{\"itemprop\":\"name\",\"class\":\"cmp-CompanyWidget-name\"})\n",
    "\n",
    "#for cmp in cmp_n[1:]:\n",
    "#    print(cmp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[\"Data+Analyst\",\"Data+Engineers\",\"Database+Administrator\",\n",
    "           \"Machine+Learning+Engineer\",\"Data+Scientist\",\"Data+Architect\",\n",
    "           \"Statistician\"\"Business+Analyst\",\"Data\",\"Analytics+Manager\",\n",
    "           \"Big+Data+Engineer\",\"Database+Developer\",\"Statistician\",\n",
    "           \"Big+Data+Software+Developer\",\"Business+Analyst\",\n",
    "           \"Business+Intelligence+Analyst\",\"Analyst\",\"Analysis\",\"Python\",\"SQL\",\n",
    "           \"BI+Specialist\",\"Analytics+Manager\",\"Machine+Learning+Scientist\",\"Big+Data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_scrapping_cmp(title):\n",
    "    \n",
    "    headers = ['company']\n",
    "    query = title\n",
    "    indeed_search = \"https://www.indeed.com/companies/search?q=\"\n",
    "    indeed_query = indeed_search + query + \"&l=&from=discovery-cmp-search\"\n",
    "\n",
    "    options = Options()\n",
    "    ua = UserAgent()\n",
    "    user_agent = ua.random\n",
    "    options.add_argument(f'user-agent={user_agent}')\n",
    "\n",
    "    driver = webdriver.Chrome(chrome_options=options, executable_path=chromedriver)\n",
    "    driver.get(indeed_query)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    \n",
    "    cmp_n=soup.find_all('a',{\"itemprop\":\"name\",\"class\":\"cmp-CompanyWidget-name\"})\n",
    "    company_name=[]\n",
    "    for cmp in cmp_n[1:]:\n",
    "        company_name.append(cmp.text)\n",
    "    headers = ['company']*len(company_name)\n",
    "    driver.quit()\n",
    "    return dict(zip(headers, [company_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_list = []\n",
    "\n",
    "for link in job_title:\n",
    "    company_list.append(web_scrapping_cmp(link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(company_list)) #23\n",
    "#company_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Indeed_Company=pd.DataFrame(company_list[0])\n",
    "for i in range(1,len(company_list)):\n",
    "    try:\n",
    "        Indeed_Company=pd.concat([Indeed_Company,pd.DataFrame(company_list[i])])\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver.quit()\n",
    "len(Indeed_Company.company.unique())\n",
    "cmps=pd.DataFrame(Indeed_Company.company.unique())\n",
    "cmps[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Company name- Method 2 from job searching page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1 = \"data-scientist\"\n",
    "indeed_search = \"https://www.indeed.com/q-\"\n",
    "indeed_query_1 = indeed_search + query_1 + \"-jobs.html\"\n",
    "indeed_query_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(chrome_options=options, executable_path=chromedriver)\n",
    "driver.get(indeed_query_1)\n",
    "next_page=driver.find_element_by_class_name('pn')\n",
    "next_page.click()\n",
    "#next_page=driver.find_element_by_class_name('pn')\n",
    "#next_page.click()\n",
    "\n",
    "next_page=driver.find_elements_by_css_selector('span.np')\n",
    "next_page[1].click()\n",
    "#<path d=\"M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6-6-6z\" fill=\"#2D2D2D\"></path>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_title=[\"data-scientist\",\"data-analyst\",\"Data-Engineers\",\"Data-Architect\",\"Database-Developer\"\n",
    "            ,\"Machine-Learning-Scientist\",\"Machine-Learning-Engineer\"]\n",
    "\n",
    "#Indeed_Company=[]\n",
    "for title in data_title:\n",
    "    query_1 = title\n",
    "    indeed_search = \"https://www.indeed.com/q-\"\n",
    "    indeed_query_1 = indeed_search + query_1 + \"-jobs.html\"\n",
    "    driver = webdriver.Chrome(chrome_options=options, executable_path=chromedriver)\n",
    "    driver.get(indeed_query_1)\n",
    "    \n",
    "    for i in range(35):\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        comp_name=soup.find_all('a', {\"data-tn-element\":\"companyName\"})\n",
    "\n",
    "        for cmp in comp_name:\n",
    "            Indeed_Company.append(cmp.text.replace(\"\\n\",\"\"))\n",
    "            \n",
    "        time.sleep(2)\n",
    "        \n",
    "        if i==0:\n",
    "            next_page=driver.find_element_by_class_name('np')\n",
    "            next_page.click()\n",
    "        else:\n",
    "            try:\n",
    "                next_page=driver.find_elements_by_css_selector('span.np')\n",
    "                next_page[1].click()\n",
    "            except Exception:\n",
    "                pass\n",
    "    driver.quit()\n",
    "    time.sleep(300)\n",
    "\n",
    "print(len(Indeed_Company))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver.quit()\n",
    "print(len(pd.DataFrame(Indeed_Company)[0].unique()))\n",
    "new_company_list= pd.concat([cmps,pd.DataFrame(Indeed_Company)])\n",
    "new_company_list=pd.DataFrame(new_company_list[0].unique())\n",
    "new_company_list.to_csv('new_company_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Salary page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"Paypal/salaries\"\n",
    "indeed_search = \"https://www.indeed.com/cmp/\"\n",
    "indeed_query1 = indeed_search + query1 +\"?job_category=math\"\n",
    "indeed_query1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_useragent import UserAgent\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "options = Options()\n",
    "ua = UserAgent()\n",
    "user_agent = ua.random\n",
    "options.add_argument(f'user-agent={user_agent}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First we launch the indeed page through our ChromeDrive. \n",
    "(A new browser should pop up. To continue using Selenium, keep this window open!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(chrome_options=options, executable_path=chromedriver)\n",
    "driver.get(indeed_query1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Title/Salary/hourly or year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=soup.find_all('span')\n",
    "\n",
    "for a1 in a:\n",
    "    try:\n",
    "        a2=a1.text.split(\" \")\n",
    "        if a2[1]=='per':\n",
    "            print(a2[0], a2[1]+\" \"+a2[2])\n",
    "    except Exception:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('div', class_=\"cmp-SalarySummaryTitle\")[0].find('a').text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary=soup.find_all('span')\n",
    "title=soup.find_all('div', class_=\"cmp-SalarySummaryTitle\")\n",
    "\n",
    "i=0\n",
    "for salary1 in salary:\n",
    "    try:\n",
    "        salary2=salary1.text.split(\" \")\n",
    "        if salary2[1]=='per':\n",
    "            print(salary2[0], salary2[1]+\" \"+salary2[2])\n",
    "            print(title[i].find('a').text)\n",
    "            i+=1\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salary Satisfication rate %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salary_sat=soup.find('div',class_=\"cmp-SalarySatisfactionSidebarWidgetPieChart-inside\").text\n",
    "salary_sat=soup.find('div',class_=\"cmp-SalarySatisfactionSidebarWidgetPieChart-inside\").text\n",
    "salary_sat=int(salary_sat.replace(\"%\",\"\"))\n",
    "salary_sat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Company Rating value & benefit rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_rating=float(soup.find('span', {\"aria-hidden\":\"true\", \"class\":\"cmp-CompactHeaderCompanyRatings-value\"}).text)\n",
    "cmp_rating                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"Paypal\"\n",
    "indeed_search = \"https://www.indeed.com/cmp/\"\n",
    "indeed_query1 = indeed_search + query1\n",
    "\n",
    "#driver = webdriver.Chrome(chrome_options=options, executable_path=chromedriver)\n",
    "#driver.get(indeed_query1)\n",
    "#soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "benefit_rating=float(soup.find_all('span', {\"aria-hidden\":\"true\",\"class\":\"css-3xwreb e1wnkr790\"})[1].text)\n",
    "print(benefit_rating)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Company home page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_2 = \"Paypal\"\n",
    "indeed_search_2 = \"https://www.indeed.com/cmp/\"\n",
    "indeed_query_2 = indeed_search_2 + query_2 + \"/about?from=acme-wonder\"\n",
    "print(indeed_query_2)\n",
    "driver.get(indeed_query_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_2 = BeautifulSoup(driver.page_source, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Headquarters/Revenue/company size/ Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Headquarters_State=soup_2.find(\"div\",{\"class\":\"cmp-AboutBasicCompanyDetailsWidget-content\",\n",
    "                   \"data-testid\":\"headquarters\"}).text.split(',')[1]\n",
    "\n",
    "Headquarters_City=soup_2.find(\"div\",{\"class\":\"cmp-AboutBasicCompanyDetailsWidget-content\",\n",
    "                   \"data-testid\":\"headquarters\"}).text.split(',')[0]\n",
    "\n",
    "#Headquarters_Country=soup_2.find(\"div\",{\"class\":\"cmp-AboutBasicCompanyDetailsWidget-content\",\n",
    "#                   \"data-testid\":\"headquarters\"}).text.split(',')[2]\n",
    "\n",
    "Revenue= soup_2.find(\"div\",{\"class\":\"cmp-AboutBasicCompanyDetailsWidget-content\", \"data-testid\":\"revenue\"}).text\n",
    "\n",
    "\n",
    "Cmp_size=soup_2.find(\"div\",{\"class\":\"cmp-AboutBasicCompanyDetailsWidget-content\",\"data-testid\":\"employees\"}).text\n",
    "\n",
    "Industry= soup_2.find(\"div\",{\"class\":\"cmp-AboutBasicCompanyDetailsWidget-content\",\"data-testid\":\"revenue\"}).text\n",
    "\n",
    "print(Headquarters_State,Headquarters_City, Cmp_size,Revenue,Industry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Company Interview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_3 = \"Paypal/interviews\"\n",
    "indeed_search_3 = \"https://www.indeed.com/cmp/\"\n",
    "indeed_query_3 = indeed_search_3 + query_3\n",
    "print(indeed_query_3)\n",
    "driver.get(indeed_query_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_3 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get Interview difficulty & length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_diff=soup_3.find('div',{\"class\":\"cmp-DifficultyCard-result\",\n",
    "                       \"data-testid\":\"cmp-InterviewSummaryCard-result\"}).text\n",
    "print(inter_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_len=soup_3.find('div',{\"class\":\"cmp-DurationCard-text\",\n",
    "                       \"data-testid\":\"cmp-InterviewSummaryCard-result\"}).text\n",
    "print(inter_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Function to web scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_scrapping(cmp):\n",
    "    \n",
    "    headers = ['company','Headquarters_State', 'Headquarters_City', 'revenue', \n",
    "               'cmp_size', 'industry','salary_sat', 'inter_diff','inter_len','title', 'salary', 'salary_unit',\n",
    "              \"cmp_rating\",\"benefit_rating\"]\n",
    "    \n",
    "    cmp1=cmp.replace(\" \", \"-\")\n",
    "    \n",
    "    try:\n",
    "        query1 = cmp1+\"/salaries\"\n",
    "        indeed_search = \"https://www.indeed.com/cmp/\"\n",
    "        indeed_query1 = indeed_search + query1 +\"?job_category=math\"\n",
    "        driver.get(indeed_query1)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        ###Get Title/Salary/hourly or year\n",
    "        salary_span=soup.find_all('span')\n",
    "        title1=soup.find_all('div', class_=\"cmp-SalarySummaryTitle\")\n",
    "        \n",
    "        salary=[]\n",
    "        salary_unit=[]\n",
    "        title=[]\n",
    "        \n",
    "        i=0\n",
    "        for salary1 in salary_span:\n",
    "            try:\n",
    "                salary2=salary1.text.split(\" \")\n",
    "                if salary2[1]=='per':\n",
    "                    salary.append(salary2[0])\n",
    "                    salary_unit.append(salary2[1]+\" \"+salary2[2])\n",
    "                    title.append(title1[i].find('a').text)\n",
    "                    i+=1\n",
    "            except Exception:\n",
    "                pass\n",
    "        ###Get Salary Satisfication rate %\n",
    "        salary_sat=soup.find('div',class_=\"cmp-SalarySatisfactionSidebarWidgetPieChart-inside\").text\n",
    "        salary_sat_div=int(salary_sat.replace(\"%\",\"\"))\n",
    "        salary_sat=[salary_sat_div]*len(salary)\n",
    "        cmp_rating=[float(soup.find('span', {\"aria-hidden\":\"true\", \n",
    "                                             \"class\":\"cmp-CompactHeaderCompanyRatings-value\"}).text)]*len(salary)\n",
    "        \n",
    "        \n",
    "        query1 = cmp1\n",
    "        indeed_search = \"https://www.indeed.com/cmp/\"\n",
    "        indeed_query1 = indeed_search + query1\n",
    "        driver.get(indeed_query1)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        benefit_rating=[float(soup.find_all('span', {\"aria-hidden\":\"true\",\"class\":\"css-3xwreb e1wnkr790\"})[1].text)]*len(salary)\n",
    "\n",
    "        ###Get Headquarters/Revenue/company size/ Industry\n",
    "        query_2 = cmp1\n",
    "        indeed_search_2 = \"https://www.indeed.com/cmp/\"\n",
    "        indeed_query_2 = indeed_search_2 + query_2 + \"/about?from=acme-wonder\"\n",
    "        driver.get(indeed_query_2)\n",
    "        soup_2 = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    " \n",
    "        try:     \n",
    "            Headquarters_State=[soup_2.find(\"div\",{\"class\":\"cmp-AboutBasicCompanyDetailsWidget-content\",\n",
    "                                                  \"data-testid\":\"headquarters\"}).text.split(',')[1]]*len(salary)\n",
    "        except Exception:\n",
    "            Headquarters_State=np.nan*len(salary)\n",
    "\n",
    "        try:\n",
    "            Headquarters_City=[soup_2.find(\"div\",{\"class\":\"cmp-AboutBasicCompanyDetailsWidget-content\",\n",
    "                                                 \"data-testid\":\"headquarters\"}).text.split(',')[0]]*len(salary)\n",
    "        except Exception:\n",
    "            Headquarters_City=np.nan*len(salary)\n",
    "            \n",
    "        try:    \n",
    "            revenue= [soup_2.find(\"div\",{\"class\":\"cmp-AboutBasicCompanyDetailsWidget-content\", \n",
    "                                        \"data-testid\":\"revenue\"}).text]*len(salary)\n",
    "        except Exception:\n",
    "            revenue=np.nan*len(salary) \n",
    "            \n",
    "        try:\n",
    "            cmp_size=[soup_2.find(\"div\",{\"class\":\"cmp-AboutBasicCompanyDetailsWidget-content\",\n",
    "                                         \"data-testid\":\"employees\"}).text]*len(salary)\n",
    "        except Exception:\n",
    "            cmp_size=np.nan*len(salary) \n",
    "            \n",
    "        try:\n",
    "            industry= [soup_2.find(\"div\",{\"class\":\"cmp-AboutBasicCompanyDetailsWidget-content\",\n",
    "                                          \"data-testid\":\"revenue\"}).text]*len(salary)\n",
    "        except Exception:\n",
    "            industry=np.nan*len(salary) \n",
    "    \n",
    "        ###Get Interview difficulty & length\n",
    "        query_3 = cmp1 + \"/interviews\"\n",
    "        indeed_search_3 = \"https://www.indeed.com/cmp/\"\n",
    "        indeed_query_3 = indeed_search_3 + query_3\n",
    "        driver.get(indeed_query_3)\n",
    "        soup_3 = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        try:\n",
    "            inter_diff=[soup_3.find('div',{\"class\":\"cmp-DifficultyCard-result\",\n",
    "                           \"data-testid\":\"cmp-InterviewSummaryCard-result\"}).text]*len(salary)\n",
    "        except Exception:\n",
    "            inter_diff=\"none\"*len(salary)\n",
    "            \n",
    "        try:\n",
    "            inter_len=[soup_3.find('div',{\"class\":\"cmp-DurationCard-text\",\n",
    "                           \"data-testid\":\"cmp-InterviewSummaryCard-result\"}).text]*len(salary)\n",
    "        except Exception:\n",
    "            inter_len=\"none\"*len(salary)\n",
    "        \n",
    "        \n",
    "        company=[cmp]*len(salary)\n",
    "        return dict(zip(headers, [company,Headquarters_State, Headquarters_City, revenue, \n",
    "               cmp_size, industry,salary_sat, inter_diff,inter_len,title, salary, salary_unit,cmp_rating,benefit_rating]))\n",
    "\n",
    "\n",
    "    except Exception:\n",
    "        return dict(zip(headers, [cmp, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For loop-web_scrapping function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#indeed_data = []\n",
    "change_user=0\n",
    "sleep_time=0\n",
    "\n",
    "for link in new_company_list[0][3:]:\n",
    "\n",
    "    if change_user==0:\n",
    "        options = Options()\n",
    "        ua = UserAgent()\n",
    "        user_agent = ua.random\n",
    "        options.add_argument(f'user-agent={user_agent}')\n",
    "        driver = webdriver.Chrome(chrome_options=options, executable_path=chromedriver)\n",
    "\n",
    "    else:\n",
    "        driver.quit()\n",
    "        options = Options()\n",
    "        ua = UserAgent()\n",
    "        user_agent = ua.random\n",
    "        options.add_argument(f'user-agent={user_agent}')\n",
    "        driver = webdriver.Chrome(chrome_options=options, executable_path=chromedriver)\n",
    "\n",
    "    change_user+=1\n",
    "    sleep_time+=1\n",
    " \n",
    "    indeed_data.append(web_scrapping(link))\n",
    "    if sleep_time % 10==0:\n",
    "        time.sleep(30+5*random.random())\n",
    "        \n",
    "    if sleep_time % 100==0:\n",
    "        time.sleep(300)\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indeed_data_1=[]\n",
    "change_user=1\n",
    "sleep_time=1\n",
    "\n",
    "for link in issue_cmp[3:]:\n",
    "\n",
    "    if change_user==0:\n",
    "        options = Options()\n",
    "        ua = UserAgent()\n",
    "        user_agent = ua.random\n",
    "        options.add_argument(f'user-agent={user_agent}')\n",
    "        driver = webdriver.Chrome(chrome_options=options, executable_path=chromedriver)\n",
    "\n",
    "    else:\n",
    "        driver.quit()\n",
    "        options = Options()\n",
    "        ua = UserAgent()\n",
    "        user_agent = ua.random\n",
    "        options.add_argument(f'user-agent={user_agent}')\n",
    "        driver = webdriver.Chrome(chrome_options=options, executable_path=chromedriver)\n",
    "\n",
    "    change_user+=1\n",
    "    sleep_time+=1\n",
    " \n",
    "    indeed_data_1.append(web_scrapping1(link))\n",
    "    if sleep_time % 50==0:\n",
    "        time.sleep(30+5*random.random())\n",
    "        \n",
    "    if sleep_time % 200==0:\n",
    "        time.sleep(300)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indeed_data_1)\n",
    "c=pd.DataFrame(indeed_data_1[0])\n",
    "for i in range(1,len(indeed_data_1)):\n",
    "    try:\n",
    "        Indeed_Company_Salary_1=pd.concat([Indeed_Company_Salary_1,pd.DataFrame(indeed_data_1[i])])\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#company_list.remove_all(None)\n",
    "#print(company_list)\n",
    "\n",
    "Indeed_Company_Salary=pd.DataFrame(indeed_data[0])\n",
    "for i in range(1,len(indeed_data)):\n",
    "    try:\n",
    "        Indeed_Company_Salary=pd.concat([Indeed_Company_Salary,pd.DataFrame(indeed_data[i])])\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Indeed_Company_Salary.shape)\n",
    "\n",
    "Indeed_Company_Salary.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Indeed_Company_Salary.to_csv('Indeed_Company_Salary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indeed_Company_Salary=pd.read_csv(\"Indeed_Company_Salary_revised.csv\")\n",
    "\n",
    "#Indeed_Company_Salary=pd.concat([Indeed_Company_Salary,Indeed_Company_Salary_1])\n",
    "\n",
    "#Indeed_Company_Salary.to_csv('Indeed_Company_Salary.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the company without data, and rerun webscrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(indeed_data))\n",
    "empty=[]\n",
    "for i,a in enumerate(indeed_data):\n",
    "    if a==({'company': [],'Headquarters_State': [],\n",
    "                   'Headquarters_City': [],'revenue': [],'cmp_size': [],'industry': [],\n",
    "                   'salary_sat': [],'inter_diff': [],'inter_len': [],'title': [],'salary': [],\n",
    "                   'salary_unit': [],'cmp_rating': [],'benefit_rating': []}):\n",
    "        empty.append(i)\n",
    "\n",
    "empty=np.array(empty)+1    \n",
    "empty\n",
    "\n",
    "issue_cmp=new_company_list[0][empty]\n",
    "len(issue_cmp)\n",
    "print(issue_cmp)\n",
    "\n",
    "\n",
    "#indeed_data.index({'company': [],'Headquarters_State': [],\n",
    "#                   'Headquarters_City': [],'revenue': [],'cmp_size': [],'industry': [],\n",
    "#                   'salary_sat': [],'inter_diff': [],'inter_len': [],'title': [],'salary': [],\n",
    "#                   'salary_unit': [],'cmp_rating': [],'benefit_rating': []})\n",
    "#for i in range(13):\n",
    "#    print(indeed_data[i]['company'])\n",
    "#new_company_list[0][13]\n",
    "#indeed_data[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Founded year & industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company=Indeed_Company_Salary['company'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(chrome_options=options, executable_path=chromedriver)\n",
    "query=company[1].replace(\" \",\"-\")\n",
    "indeed_search = \"https://www.indeed.com/cmp/\"\n",
    "indeed_query = indeed_search + query\n",
    "driver.get(indeed_query)\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def found_industry(cmp):\n",
    "    try:\n",
    "        header=[\"company\",\"founded\",\"industry\"]\n",
    "        company=cmp\n",
    "\n",
    "        query=cmp.replace(\" \",\"-\")\n",
    "        indeed_search = \"https://www.indeed.com/cmp/\"\n",
    "        indeed_query = indeed_search + query\n",
    "        driver.get(indeed_query)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        founded=soup.find('li', {\"data-testid\":\"companyInfo-founded\", \"class\":\"css-v4e08k eu4oa1w0\"}).text\n",
    "        founded=int(founded.replace(\"Founded\",\"\"))\n",
    "\n",
    "        industry=soup.find('li', {\"data-testid\":\"companyInfo-industry\", \"class\":\"css-v4e08k eu4oa1w0\"}).text\n",
    "        industry=industry.replace(\"Industry\",\"\")\n",
    "\n",
    "\n",
    "        return dict(zip(header, [company,founded, industry]))\n",
    "\n",
    "\n",
    "    except Exception:\n",
    "        return dict(zip(headers, [cmp, 0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_user=0\n",
    "sleep_time=0\n",
    "indeed_data_2=[]\n",
    "\n",
    "for link in company[0:]:\n",
    "\n",
    "    if change_user==0:\n",
    "        options = Options()\n",
    "        ua = UserAgent()\n",
    "        user_agent = ua.random\n",
    "        options.add_argument(f'user-agent={user_agent}')\n",
    "        driver = webdriver.Chrome(chrome_options=options, executable_path=chromedriver)\n",
    "\n",
    "    else:\n",
    "        driver.quit()\n",
    "        options = Options()\n",
    "        ua = UserAgent()\n",
    "        user_agent = ua.random\n",
    "        options.add_argument(f'user-agent={user_agent}')\n",
    "        driver = webdriver.Chrome(chrome_options=options, executable_path=chromedriver)\n",
    "\n",
    "    change_user+=1\n",
    "    sleep_time+=1\n",
    " \n",
    "    indeed_data_2.append(found_industry(link))\n",
    "    if sleep_time % 50==0:\n",
    "        time.sleep(20+5*random.random())\n",
    "        \n",
    "    if sleep_time % 200==0:\n",
    "        time.sleep(300)\n",
    "driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indeed_data_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "industry_found=pd.DataFrame(indeed_data_2[0],index=[0])\n",
    "\n",
    "for i in range(1,len(indeed_data_2)):\n",
    "    try:\n",
    "        industry_found=pd.concat([industry_found,pd.DataFrame(indeed_data_2[i],index=[i])])\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "industry_found.to_csv('industry_found.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([industry_found,pd.DataFrame(indeed_data_2[1],index=[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
